{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : Diffusion Models that creates the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n",
    "        print(f\"GPU memory cached: {torch.cuda.memory_reserved()/1e9:.2f}GB\")\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, channels, num_heads=8, reduction_factor=2):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Downsampling\n",
    "        self.down = nn.Conv2d(channels, channels, kernel_size=3, \n",
    "                             stride=reduction_factor, padding=1)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up = nn.ConvTranspose2d(channels, channels, kernel_size=4,\n",
    "                                    stride=reduction_factor, padding=1)\n",
    "        \n",
    "        # Transformer components\n",
    "        self.norm1 = nn.GroupNorm(8, channels)\n",
    "        self.norm2 = nn.GroupNorm(8, channels)\n",
    "        self.self_attention = nn.MultiheadAttention(channels, num_heads)\n",
    "        \n",
    "        # MLP block\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels * 4, channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        identity = x\n",
    "        \n",
    "        # Downsampling\n",
    "        x = self.down(x)\n",
    "        \n",
    "        # Normalization\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # Reshape per attention\n",
    "        _, _, h_down, w_down = x.shape\n",
    "        x_flat = x.flatten(2).permute(2, 0, 1)  # (h*w, batch, channels)\n",
    "        \n",
    "        # Self attention\n",
    "        attn_output, _ = self.self_attention(x_flat, x_flat, x_flat)\n",
    "        \n",
    "        # Reshape back e prima skip connection\n",
    "        x = attn_output.permute(1, 2, 0).view(b, c, h_down, w_down) + x\n",
    "        \n",
    "        # MLP\n",
    "        x = self.norm2(x)\n",
    "        x_mlp = x.view(b, c, -1).permute(0, 2, 1)\n",
    "        x_mlp = self.mlp(x_mlp)\n",
    "        x = x + x_mlp.permute(0, 2, 1).view(b, c, h_down, w_down)\n",
    "        \n",
    "        # Upsampling e seconda skip connection\n",
    "        x = self.up(x)\n",
    "        return x + identity\n",
    "\n",
    "class E2GANGenerator(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, 7, padding=3),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Downsampling\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.res1 = ResidualBlock(256)\n",
    "        self.res2 = ResidualBlock(256)\n",
    "        \n",
    "        # Transformer block\n",
    "        self.transformer = TransformerBlock(256)\n",
    "        \n",
    "        # Third residual block\n",
    "        self.res3 = ResidualBlock(256)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Output convolution\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(64, output_channels, 7, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        \n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.res3(x)\n",
    "        \n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "\n",
    "class ImagePairsDataset(Dataset):\n",
    "    def __init__(self, originals_dir, filtered_dir, transform=None):\n",
    "        self.originals_dir = originals_dir\n",
    "        self.filtered_dir = filtered_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = sorted(os.listdir(originals_dir))  # Sorted per riproducibilit√†\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        original_path = os.path.join(self.originals_dir, image_name)\n",
    "        filtered_path = os.path.join(self.filtered_dir, image_name)\n",
    "\n",
    "        original_image = Image.open(original_path).convert(\"RGB\")\n",
    "        filtered_image = Image.open(filtered_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            original_image = self.transform(original_image)\n",
    "            filtered_image = self.transform(filtered_image)\n",
    "        \n",
    "        return original_image, filtered_image\n",
    "\n",
    "class DatasetManager:\n",
    "    def __init__(self, n_clusters=400):\n",
    "        self.feature_extractor = resnet50(pretrained=True)\n",
    "        self.feature_extractor.eval()\n",
    "        self.n_clusters = n_clusters\n",
    "        \n",
    "    def extract_features(self, dataset, batch_size=32, device='cuda'):\n",
    "        self.feature_extractor = self.feature_extractor.to(device)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "        features = []\n",
    "        \n",
    "        print(\"Extracting features...\")\n",
    "        with torch.no_grad():\n",
    "            for i, (images, _) in enumerate(dataloader):\n",
    "                images = images.to(device)\n",
    "                feat = self.feature_extractor(images)\n",
    "                features.append(feat.cpu().numpy())\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Processed {i * batch_size}/{len(dataset)} images\")\n",
    "                \n",
    "        return np.concatenate(features)\n",
    "    \n",
    "    def create_clustered_dataset(self, original_dataset):\n",
    "        features = self.extract_features(original_dataset)\n",
    "        features = features.reshape(features.shape[0], -1)\n",
    "        \n",
    "        print(f\"Running K-means clustering with {self.n_clusters} clusters...\")\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10)\n",
    "        clusters = kmeans.fit_predict(features)\n",
    "        \n",
    "        selected_indices = []\n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_points = features[clusters == i]\n",
    "            cluster_indices = np.where(clusters == i)[0]\n",
    "            \n",
    "            if len(cluster_points) > 0:\n",
    "                centroid = kmeans.cluster_centers_[i]\n",
    "                distances = np.linalg.norm(cluster_points - centroid, axis=1)\n",
    "                closest_idx = cluster_indices[np.argmin(distances)]\n",
    "                selected_indices.append(closest_idx)\n",
    "            \n",
    "        print(f\"Selected {len(selected_indices)} representative samples\")\n",
    "        return torch.utils.data.Subset(original_dataset, selected_indices)\n",
    "\n",
    "def measure_inference_speed(generator, device, n_samples=100):\n",
    "    generator.eval()\n",
    "    dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    print(\"Warming up...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = generator(dummy_input)\n",
    "    \n",
    "    # Misura reale\n",
    "    print(f\"Measuring inference time over {n_samples} samples...\")\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "            _ = generator(dummy_input)\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            times.append((end - start) * 1000)  # ms\n",
    "            \n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    print(f\"Average inference time: {avg_time:.2f}ms ¬± {std_time:.2f}ms\")\n",
    "    return avg_time\n",
    "\n",
    "def save_sample_images(generator, val_loader, epoch, save_dir, device):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        real_A, real_B = next(iter(val_loader))\n",
    "        real_A, real_B = real_A.to(device), real_B.to(device)\n",
    "        fake_B = generator(real_A)\n",
    "        \n",
    "        # Denormalize\n",
    "        def denorm(x):\n",
    "            return (x + 1) / 2\n",
    "            \n",
    "        # Salva griglia\n",
    "        img_sample = torch.cat([\n",
    "            denorm(real_A), \n",
    "            denorm(fake_B), \n",
    "            denorm(real_B)\n",
    "        ], -2)\n",
    "        \n",
    "        save_image(img_sample, \n",
    "                  f\"{save_dir}/epoch_{epoch}.png\", \n",
    "                  nrow=min(8, real_A.size(0)), \n",
    "                  normalize=False)\n",
    "\n",
    "def calculate_fid(real_features, fake_features):\n",
    "    try:\n",
    "        if np.isnan(real_features).any() or np.isnan(fake_features).any():\n",
    "            return float('inf')\n",
    "            \n",
    "        eps = 1e-6\n",
    "        \n",
    "        mu1 = np.mean(real_features, axis=0)\n",
    "        sigma1 = np.cov(real_features, rowvar=False) + np.eye(real_features.shape[1]) * eps\n",
    "        \n",
    "        mu2 = np.mean(fake_features, axis=0)\n",
    "        sigma2 = np.cov(fake_features, rowvar=False) + np.eye(fake_features.shape[1]) * eps\n",
    "        \n",
    "        diff = mu1 - mu2\n",
    "        \n",
    "        covmean = sqrtm(sigma1.dot(sigma2))\n",
    "        \n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "            \n",
    "        fid = np.sum(diff**2) + np.trace(sigma1 + sigma2 - 2*covmean)\n",
    "        return float(fid)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in FID calculation: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "def evaluate_model(generator, dataloader, device):\n",
    "    generator.eval()\n",
    "    feature_extractor = resnet50(pretrained=True).to(device)\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    real_features = []\n",
    "    fake_features = []\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (real_A, real_B) in enumerate(dataloader):\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "            \n",
    "            fake_B = generator(real_A)\n",
    "            \n",
    "            real_feat = feature_extractor(real_B)\n",
    "            fake_feat = feature_extractor(fake_B)\n",
    "            \n",
    "            real_features.append(real_feat.cpu().numpy())\n",
    "            fake_features.append(fake_feat.cpu().numpy())\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f\"Processed {i * dataloader.batch_size}/{len(dataloader.dataset)} images\")\n",
    "    \n",
    "    if len(real_features) == 0 or len(fake_features) == 0:\n",
    "        return float('inf')\n",
    "        \n",
    "    real_features = np.concatenate(real_features)\n",
    "    fake_features = np.concatenate(fake_features)\n",
    "    \n",
    "    return calculate_fid(real_features, fake_features)\n",
    "\n",
    "\n",
    "def train_e2gan(generator, discriminator, train_loader, val_loader, num_epochs, device, save_dir):\n",
    "    # Parameters come nel paper\n",
    "    criterion_GAN = torch.nn.MSELoss()\n",
    "    criterion_pixel = torch.nn.L1Loss()\n",
    "    lambda_pixel = 100\n",
    "\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "    # Metrics tracking\n",
    "    best_fid = float('inf')\n",
    "    metrics = {\n",
    "        'g_losses': [],\n",
    "        'd_losses': [],\n",
    "        'pixel_losses': [],\n",
    "        'fid_scores': [],\n",
    "        'epoch_times': [],\n",
    "        'running_times': []\n",
    "    }\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        \n",
    "        epoch_g_losses = []\n",
    "        epoch_d_losses = []\n",
    "        epoch_pixel_losses = []\n",
    "        \n",
    "        for i, (real_A, real_B) in enumerate(train_loader):\n",
    "            batch_size = real_A.size(0)\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "\n",
    "            # Ground truths\n",
    "            valid = torch.ones((batch_size, 1, 16, 16), requires_grad=False).to(device)\n",
    "            fake = torch.zeros((batch_size, 1, 16, 16), requires_grad=False).to(device)\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            fake_B = generator(real_A)\n",
    "            pred_fake = discriminator(fake_B, real_A)\n",
    "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "            loss_pixel = criterion_pixel(fake_B, real_B)\n",
    "            loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "            pred_real = discriminator(real_B, real_A)\n",
    "            loss_real = criterion_GAN(pred_real, valid)\n",
    "            pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "            loss_fake = criterion_GAN(pred_fake, fake)\n",
    "            loss_D = (loss_real + loss_fake) / 2\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Save losses\n",
    "            epoch_g_losses.append(loss_G.item())\n",
    "            epoch_d_losses.append(loss_D.item())\n",
    "            epoch_pixel_losses.append(loss_pixel.item())\n",
    "\n",
    "            # Print progress\n",
    "            if i % 5 == 0:\n",
    "                print(f\"\\rEpoch [{epoch}/{num_epochs}] Batch [{i}/{len(train_loader)}] \"\n",
    "                      f\"d_loss: {loss_D.item():.4f}, g_loss: {loss_G.item():.4f}, \"\n",
    "                      f\"pixel: {loss_pixel.item():.4f}\", end=\"\")\n",
    "\n",
    "        # End of epoch\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        running_time = time.time() - total_start_time\n",
    "        \n",
    "        metrics['epoch_times'].append(epoch_time)\n",
    "        metrics['running_times'].append(running_time)\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_g_loss = np.mean(epoch_g_losses)\n",
    "        avg_d_loss = np.mean(epoch_d_losses)\n",
    "        avg_pixel_loss = np.mean(epoch_pixel_losses)\n",
    "        \n",
    "        metrics['g_losses'].append(avg_g_loss)\n",
    "        metrics['d_losses'].append(avg_d_loss)\n",
    "        metrics['pixel_losses'].append(avg_pixel_loss)\n",
    "\n",
    "        # Validation and FID calculation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        generator.eval()\n",
    "        val_fid = evaluate_model(generator, val_loader, device)\n",
    "        metrics['fid_scores'].append(val_fid)\n",
    "        \n",
    "        # Save sample images\n",
    "        if epoch % 5 == 0:\n",
    "            save_sample_images(generator, val_loader, epoch, save_dir, device)\n",
    "\n",
    "        # Save best model\n",
    "        if val_fid < best_fid:\n",
    "            best_fid = val_fid\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                'metrics': metrics,\n",
    "            }, f'{save_dir}/best_model.pt')\n",
    "            print(f\"Saved best model with FID: {val_fid:.4f}\")\n",
    "\n",
    "        # Save checkpoint ogni 10 epoche\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                'metrics': metrics,\n",
    "            }, f'{save_dir}/checkpoint_epoch_{epoch+1}.pt')\n",
    "\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch} Summary:\")\n",
    "        print(f\"D Loss: {avg_d_loss:.4f}, G Loss: {avg_g_loss:.4f}, Pixel Loss: {avg_pixel_loss:.4f}\")\n",
    "        print(f\"FID Score: {val_fid:.4f}\")\n",
    "        print(f\"Epoch Time: {epoch_time:.2f}s, Total Time: {running_time/60:.2f}m\")\n",
    "        print_gpu_memory()\n",
    "\n",
    "    return generator, discriminator, metrics\n",
    "\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    num_epochs = 100\n",
    "    batch_size = 32  # Ottimizzato per T4\n",
    "    image_size = 256\n",
    "    n_clusters = 400  # Come nel paper\n",
    "    \n",
    "    # Setup CUDA e reproducibility\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(42)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create run directory\n",
    "    run_name = f\"e2gan_single_concept_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "    save_dir = f\"results/{run_name}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Dataset transforms\n",
    "    transforms_ = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size), Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    full_dataset = ImagePairsDataset(\n",
    "        originals_dir='/kaggle/input/images/original_images',  # Modifica questo\n",
    "        filtered_dir='/kaggle/input/images/modified_images',   # Modifica questo\n",
    "        transform=transforms_\n",
    "    )\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = int(0.1 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset sizes - Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
    "    \n",
    "    # Create clustered dataset\n",
    "    print(\"Creating clustered dataset...\")\n",
    "    dataset_manager = DatasetManager(n_clusters=n_clusters)\n",
    "    train_clustered = dataset_manager.create_clustered_dataset(train_dataset)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_clustered,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize models\n",
    "    print(\"Initializing models...\")\n",
    "    generator = E2GANGenerator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    \n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)\n",
    "    \n",
    "    # Print initial GPU memory usage\n",
    "    print(\"Initial GPU memory usage:\")\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    # Measure initial inference time\n",
    "    print(\"\\nMeasuring initial inference time...\")\n",
    "    initial_inf_time = measure_inference_speed(generator, device)\n",
    "    \n",
    "    # Training\n",
    "    print(\"\\nStarting training...\")\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    generator, discriminator, metrics = train_e2gan(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        num_epochs,\n",
    "        device,\n",
    "        save_dir\n",
    "    )\n",
    "    \n",
    "    total_training_time = time.time() - training_start_time\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\nFinal evaluation:\")\n",
    "    test_fid = evaluate_model(generator, test_loader, device)\n",
    "    final_inf_time = measure_inference_speed(generator, device)\n",
    "    \n",
    "    # Save final results\n",
    "    final_results = {\n",
    "        'test_fid': float(test_fid),\n",
    "        'initial_inference_time_ms': float(initial_inf_time),\n",
    "        'final_inference_time_ms': float(final_inf_time),\n",
    "        'total_training_time_minutes': float(total_training_time/60),\n",
    "        'gpu_memory_gb': float(torch.cuda.max_memory_allocated()/1e9),\n",
    "        'metrics': metrics\n",
    "    }\n",
    "    \n",
    "    with open(f'{save_dir}/final_results.json', 'w') as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Total training time: {total_training_time/60:.2f} minutes\")\n",
    "    print(f\"Final test FID: {test_fid:.4f}\")\n",
    "    print(f\"Final inference time: {final_inf_time:.2f}ms\")\n",
    "    print(f\"Results saved in: {save_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
