{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : Diffusion Models that creates the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import itertools\n",
    "import torch.cuda.amp as amp\n",
    "import gc\n",
    "\n",
    "# Ottimizzazioni per CUDA\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "class Config:\n",
    "    # Dataset parameters\n",
    "    MAX_IMAGES = 100          # Usiamo solo 10 immagini per il test\n",
    "    IMAGE_SIZE = 128         # Riduciamo la dimensione delle immagini\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 2          # Batch size molto piccolo\n",
    "    NUM_EPOCHS = 3          # Poche epoche per il test\n",
    "    BASE_CHANNELS = 32      # Riduciamo i canali base (era 64)\n",
    "    \n",
    "    # Model parameters\n",
    "    USE_AMP = True         # Usiamo mixed precision\n",
    "    PIN_MEMORY = True      \n",
    "    NUM_WORKERS = 0        # Disabilitiamo il multiprocessing per il test\n",
    "    \n",
    "    # Paths\n",
    "    ORIGINALS_DIR = '/kaggle/input/images/original_images'\n",
    "    FILTERED_DIR = '/kaggle/input/images/modified_images'\n",
    "\n",
    "class ImagePairsDataset(Dataset):\n",
    "    def __init__(self, originals_dir, filtered_dir, transform=None):\n",
    "        self.originals_dir = originals_dir\n",
    "        self.filtered_dir = filtered_dir\n",
    "        self.transform = transform\n",
    "        # Prendiamo solo le prime MAX_IMAGES immagini\n",
    "        self.image_names = os.listdir(originals_dir)[:Config.MAX_IMAGES]\n",
    "        print(f\"Loading {len(self.image_names)} images\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        original_path = os.path.join(self.originals_dir, image_name)\n",
    "        filtered_path = os.path.join(self.filtered_dir, image_name)\n",
    "\n",
    "        original_image = Image.open(original_path).convert('RGB')\n",
    "        filtered_image = Image.open(filtered_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            original_image = self.transform(original_image)\n",
    "            filtered_image = self.transform(filtered_image)\n",
    "        \n",
    "        return original_image, filtered_image\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.InstanceNorm2d(channels)\n",
    "        self.norm2 = nn.InstanceNorm2d(channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.norm1(self.conv1(x)))\n",
    "        out = self.norm2(self.conv2(out))\n",
    "        out = out + residual\n",
    "        return F.relu(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, channels, num_heads=8):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Self-attention\n",
    "        self.self_attention = nn.MultiheadAttention(channels, num_heads)\n",
    "        \n",
    "        # Cross-attention\n",
    "        self.cross_attention = nn.MultiheadAttention(channels, num_heads)\n",
    "        \n",
    "        # MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels * 4, channels)\n",
    "        )\n",
    "        \n",
    "        # Layer norms\n",
    "        self.norm1 = nn.LayerNorm(channels)\n",
    "        self.norm2 = nn.LayerNorm(channels)\n",
    "        self.norm3 = nn.LayerNorm(channels)\n",
    "        \n",
    "    def forward(self, x, text_features=None):\n",
    "        # Reshape for attention: [B, C, H, W] -> [H*W, B, C]\n",
    "        B, C, H, W = x.shape\n",
    "        x_flat = x.flatten(2).permute(2, 0, 1)\n",
    "        \n",
    "        # Self-attention\n",
    "        x_norm = self.norm1(x_flat)\n",
    "        sa_out, _ = self.self_attention(x_norm, x_norm, x_norm)\n",
    "        x_flat = x_flat + sa_out\n",
    "        \n",
    "        # Cross-attention with text features if provided\n",
    "        if text_features is not None:\n",
    "            x_norm = self.norm2(x_flat)\n",
    "            ca_out, _ = self.cross_attention(x_norm, text_features, text_features)\n",
    "            x_flat = x_flat + ca_out\n",
    "        \n",
    "        # MLP\n",
    "        x_norm = self.norm3(x_flat)\n",
    "        mlp_out = self.mlp(x_norm)\n",
    "        x_flat = x_flat + mlp_out\n",
    "        \n",
    "        # Reshape back: [H*W, B, C] -> [B, C, H, W]\n",
    "        x = x_flat.permute(1, 2, 0).view(B, C, H, W)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, base_channels=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, base_channels, kernel_size=7, padding=3),\n",
    "            nn.InstanceNorm2d(base_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Downsampling\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels*2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_channels*2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_channels*4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.resblocks = nn.ModuleList([\n",
    "            ResidualBlock(base_channels*4) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # Transformer block after second ResBlock\n",
    "        self.transformer = TransformerBlock(base_channels*4)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_channels*4, base_channels*2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(base_channels*2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(base_channels*2, base_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(base_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Output convolution\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, output_channels, kernel_size=7, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, text_features=None):\n",
    "        x = self.initial(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        \n",
    "        # First ResBlock\n",
    "        x = self.resblocks[0](x)\n",
    "        \n",
    "        # Second ResBlock + Transformer\n",
    "        x = self.resblocks[1](x)\n",
    "        x = self.transformer(x, text_features)\n",
    "        \n",
    "        # Third ResBlock\n",
    "        x = self.resblocks[2](x)\n",
    "        \n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=3, base_channels=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(input_channels*2, base_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        \n",
    "        # Downsampling layers\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_channels*2),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_channels*4),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*4, base_channels*8, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(base_channels*8),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Conv2d(base_channels*8, 1, kernel_size=4, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # Concatenate input image and target image\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.input(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "class GANTrainer:\n",
    "    def __init__(self, \n",
    "                 generator,\n",
    "                 discriminator,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 device,\n",
    "                 lr=2e-4,\n",
    "                 n_epochs=Config.NUM_EPOCHS,\n",
    "                 lambda_l1=100.0):\n",
    "        \n",
    "        self.generator = generator.to(device)\n",
    "        self.discriminator = discriminator.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader \n",
    "        self.device = device\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lambda_l1 = lambda_l1\n",
    "        \n",
    "        # Loss functions\n",
    "        self.criterion_gan = nn.MSELoss()\n",
    "        self.criterion_l1 = nn.L1Loss()\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), \n",
    "                                    lr=lr, betas=(0.5, 0.999))\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), \n",
    "                                    lr=lr, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Gradient scaler for mixed precision\n",
    "        self.scaler_g = amp.GradScaler()\n",
    "        self.scaler_d = amp.GradScaler()\n",
    "        \n",
    "        # Learning rate schedulers \n",
    "        def lambda_rule(epoch):\n",
    "            decay_start_epoch = self.n_epochs // 2\n",
    "            return 1.0 - max(0, epoch - decay_start_epoch) / float(self.n_epochs - decay_start_epoch + 1)\n",
    "        \n",
    "        self.scheduler_g = LambdaLR(self.optimizer_g, lr_lambda=lambda_rule)\n",
    "        self.scheduler_d = LambdaLR(self.optimizer_d, lr_lambda=lambda_rule)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # Pulizia memoria\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        total_g_loss = 0\n",
    "        total_d_loss = 0\n",
    "        n_batches = len(self.train_loader)\n",
    "        \n",
    "        for real_img, mod_img in self.train_loader:\n",
    "            batch_size = real_img.size(0)\n",
    "            real_img = real_img.to(self.device, non_blocking=True)\n",
    "            mod_img = mod_img.to(self.device, non_blocking=True)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            self.optimizer_d.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with amp.autocast():\n",
    "                fake_img = self.generator(real_img)\n",
    "                pred_fake = self.discriminator(fake_img.detach(), real_img)\n",
    "                loss_d_fake = self.criterion_gan(pred_fake, torch.zeros_like(pred_fake))\n",
    "                \n",
    "                pred_real = self.discriminator(mod_img, real_img)\n",
    "                loss_d_real = self.criterion_gan(pred_real, torch.ones_like(pred_real))\n",
    "                \n",
    "                loss_d = (loss_d_fake + loss_d_real) * 0.5\n",
    "            \n",
    "            self.scaler_d.scale(loss_d).backward()\n",
    "            self.scaler_d.step(self.optimizer_d)\n",
    "            self.scaler_d.update()\n",
    "            \n",
    "            # Train Generator\n",
    "            self.optimizer_g.zero_grad(set_to_none=True)\n",
    "            \n",
    "            with amp.autocast():\n",
    "                pred_fake = self.discriminator(fake_img, real_img)\n",
    "                loss_g_gan = self.criterion_gan(pred_fake, torch.ones_like(pred_fake))\n",
    "                \n",
    "                loss_g_l1 = self.criterion_l1(fake_img, mod_img) * self.lambda_l1\n",
    "                \n",
    "                loss_g = loss_g_gan + loss_g_l1\n",
    "            \n",
    "            self.scaler_g.scale(loss_g).backward()\n",
    "            self.scaler_g.step(self.optimizer_g)\n",
    "            self.scaler_g.update()\n",
    "            \n",
    "            total_g_loss += loss_g.item()\n",
    "            total_d_loss += loss_d.item()\n",
    "            \n",
    "        avg_g_loss = total_g_loss / n_batches\n",
    "        avg_d_loss = total_d_loss / n_batches\n",
    "        \n",
    "        return avg_g_loss, avg_d_loss\n",
    "    \n",
    "    def validate(self):\n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "        \n",
    "        total_val_loss = 0\n",
    "        n_batches = len(self.val_loader)\n",
    "        \n",
    "        with torch.no_grad(), amp.autocast():\n",
    "            for real_img, mod_img in self.val_loader:\n",
    "                real_img = real_img.to(self.device, non_blocking=True)\n",
    "                mod_img = mod_img.to(self.device, non_blocking=True)\n",
    "                \n",
    "                fake_img = self.generator(real_img)\n",
    "                val_loss = self.criterion_l1(fake_img, mod_img)\n",
    "                total_val_loss += val_loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / n_batches\n",
    "        return avg_val_loss\n",
    "    \n",
    "    def train(self):\n",
    "        best_val_loss = float('inf')\n",
    "        training_history = {\n",
    "            'g_losses': [],\n",
    "            'd_losses': [],\n",
    "            'val_losses': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            g_loss, d_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "            \n",
    "            # Update learning rates\n",
    "            self.scheduler_g.step()\n",
    "            self.scheduler_d.step()\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save({\n",
    "                    'generator_state_dict': self.generator.state_dict(),\n",
    "                    'discriminator_state_dict': self.discriminator.state_dict(),\n",
    "                    'g_optimizer_state_dict': self.optimizer_g.state_dict(),\n",
    "                    'd_optimizer_state_dict': self.optimizer_d.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                }, 'best_model.pth')\n",
    "            \n",
    "            # Store losses\n",
    "            training_history['g_losses'].append(g_loss)\n",
    "            training_history['d_losses'].append(d_loss)\n",
    "            training_history['val_losses'].append(val_loss)\n",
    "            \n",
    "            print(f\"Epoch [{epoch+1}/{self.n_epochs}] - \"\n",
    "                  f\"G_loss: {g_loss:.4f}, D_loss: {d_loss:.4f}, Val_loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Monitor GPU memory\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**2:.1f}MB / \"\n",
    "                      f\"{torch.cuda.memory_reserved() / 1024**2:.1f}MB\")\n",
    "        \n",
    "        return training_history\n",
    "\n",
    "# Inizializzazione e training\n",
    "def train_gan(train_loader, val_loader, device):\n",
    "    print(\"Initializing models...\")\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    \n",
    "    # Stampa il numero di parametri\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Generator parameters: {count_parameters(generator):,}\")\n",
    "    print(f\"Discriminator parameters: {count_parameters(discriminator):,}\")\n",
    "    \n",
    "    trainer = GANTrainer(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        lr=2e-4,\n",
    "        n_epochs=100\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    history = trainer.train()\n",
    "    return trainer, history\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Paths\n",
    "    originals_dir = '/kaggle/input/images/original_images'\n",
    "    filtered_dir = '/kaggle/input/images/modified_images'\n",
    "    \n",
    "    # Create dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = ImagePairsDataset(Config.ORIGINALS_DIR, Config.FILTERED_DIR, transform=transform)\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    train_set, val_set, test_set = random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    # DataLoader con batch size ridotto\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=Config.NUM_WORKERS,\n",
    "        pin_memory=Config.PIN_MEMORY\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.NUM_WORKERS,\n",
    "        pin_memory=Config.PIN_MEMORY\n",
    "    )\n",
    "   \n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=Config.NUM_WORKERS,\n",
    "        pin_memory=Config.PIN_MEMORY\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset sizes: Train={len(train_set)}, Val={len(val_set)}, Test={len(test_set)}\")\n",
    "     \n",
    "    # Pulisci la memoria GPU prima di iniziare\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Start training\n",
    "    trainer, history = train_gan(train_loader, val_loader, device)\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['g_losses'], label='Generator Loss')\n",
    "    plt.plot(history['d_losses'], label='Discriminator Loss')\n",
    "    plt.plot(history['val_losses'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training History')\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
